{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0616098 黃秉茂 ML HW4 SVM and ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json('train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id      cuisine                                        ingredients\n",
      "0      22675      italian  [1% low-fat cottage cheese, low-fat marinara s...\n",
      "1      32288  southern_us  [brown sugar, salt, eggs, butter, chopped peca...\n",
      "2      44406         thai  [red chili peppers, bell pepper, garlic, fish ...\n",
      "3      29355     moroccan  [water, green tea leaves, tangerine, fresh min...\n",
      "4      39350      chinese  [vegetable oil, chile sauce, tomato paste, gar...\n",
      "...      ...          ...                                                ...\n",
      "29769   2278     japanese  [soy sauce, sesame oil, garlic, sake, flour, g...\n",
      "29770    474   vietnamese  [mint, garlic sauce, chinese chives, rice nood...\n",
      "29771  44229       indian  [potatoes, vegetable broth, oil, cashew nuts, ...\n",
      "29772  20311  southern_us  [butter, powdered sugar, cream cheese, soften,...\n",
      "29773  32823      chinese  [savoy cabbage, dumpling wrappers, ginger, soy...\n",
      "\n",
      "[29774 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=dataset.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_last_word = dataset.copy()\n",
    "dataset_last_2_word = dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop redundancy and limit the number of words in a string which is in the list in a column using DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_limit = 1\n",
    "dataset_last_word[dataset_last_word.columns[-1]] = dataset_last_word[dataset_last_word.columns[-1]].apply(lambda x : [' '.join(((item.split('(')[0]).split(',')[0]).split()[-word_limit:]) for item in x])\n",
    "word_limit = 2\n",
    "dataset_last_2_word[dataset_last_2_word.columns[-1]] = dataset_last_2_word[dataset_last_2_word.columns[-1]].apply(lambda x : [' '.join(((item.split('(')[0]).split(',')[0]).split()[-word_limit:]) for item in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_shuffle = shuffle(dataset)\n",
    "dataset_last_word_shuffle = shuffle(dataset_last_word)\n",
    "dataset_last_2_word_shuffle = shuffle(dataset_last_2_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset_shuffle[dataset_shuffle.columns[-1]]\n",
    "x_last_word = dataset_last_word_shuffle[dataset_last_word_shuffle.columns[-1]]\n",
    "x_last_2_word = dataset_last_2_word_shuffle[dataset_last_2_word_shuffle.columns[-1]]\n",
    "y = dataset_shuffle[dataset_shuffle.columns[0]]\n",
    "y_last_word = dataset_last_word_shuffle[dataset_last_word_shuffle.columns[0]]\n",
    "y_last_2_word = dataset_last_2_word_shuffle[dataset_last_2_word_shuffle.columns[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data format and shape so your model can process them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot encode a series of lists in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb = MultiLabelBinarizer()\n",
    "# X = pd.DataFrame(mlb.fit_transform(x), columns=mlb.classes_, index=x.index)\n",
    "# X_last_word = pd.DataFrame(mlb.fit_transform(x_last_word), columns=mlb.classes_, index=x_last_word.index)\n",
    "# X_last_2_word = pd.DataFrame(mlb.fit_transform(x_last_2_word), columns=mlb.classes_, index=x_last_2_word.index)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(x)\n",
    "mlb_last_word = MultiLabelBinarizer()\n",
    "mlb_last_word.fit(x_last_word)\n",
    "mlb_last_2_word = MultiLabelBinarizer()\n",
    "mlb_last_2_word.fit(x_last_2_word)\n",
    "X = pd.DataFrame(mlb.transform(x), columns=mlb.classes_, index=x.index)\n",
    "X_last_word = pd.DataFrame(mlb_last_word.transform(x_last_word), columns=mlb_last_word.classes_, index=x_last_word.index)\n",
    "X_last_2_word = pd.DataFrame(mlb_last_2_word.transform(x_last_2_word), columns=mlb_last_2_word.classes_, index=x_last_2_word.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = X.astype(float)\n",
    "X_last_word = np.array(X_last_word)\n",
    "X_last_word = X_last_word.astype(float)\n",
    "X_last_2_word = np.array(X_last_2_word)\n",
    "X_last_2_word = X_last_2_word.astype(float)\n",
    "Y = np.array(y)\n",
    "Y_last_word = np.array(y_last_word)\n",
    "Y_last_2_word = np.array(y_last_2_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no word limit (29774, 6231)\n",
      "last word (29774, 1749)\n",
      "last 2 word (29774, 4897)\n"
     ]
    }
   ],
   "source": [
    "print('no word limit', X.shape)\n",
    "print('last word', X_last_word.shape)\n",
    "print('last 2 word', X_last_2_word.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Any data augmentation that can boost your final results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use PCA to get important features and alleviate amount of calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_with_proper_n_com(data, n_com_start):\n",
    "    n_com = n_com_start\n",
    "    explained_ratio = 0\n",
    "    explained_ratio_threshold = 80\n",
    "    while explained_ratio < explained_ratio_threshold:\n",
    "        n_com += 1\n",
    "        pca = PCA(n_components=n_com)\n",
    "        # calculate variance ratios\n",
    "        pca.fit(data)\n",
    "        cumulative_sum_of_variance_explained = np.cumsum(pca.explained_variance_ratio_ * 100)\n",
    "        explained_ratio = cumulative_sum_of_variance_explained[-1]\n",
    "    pca = PCA(n_components = n_com)\n",
    "    data_pca = pca.fit_transform(data)\n",
    "    return data_pca, n_com, explained_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_com: 508 explained variance ratio: 80.02014647908625\n",
      "n_com: 109 explained variance ratio: 80.00176176473056\n",
      "n_com: 384 explained variance ratio: 80.03133260816708\n"
     ]
    }
   ],
   "source": [
    "X_pca, X_proper_n_com, X_explained_ratio = pca_with_proper_n_com(X, 500)\n",
    "X_pca_last_word, X_proper_n_com_last_word, X_explained_ratio_last_word = pca_with_proper_n_com(X_last_word, 105)\n",
    "X_pca_last_2_word, X_proper_n_com_last_2_word, X_explained_ratio_last_2_word = pca_with_proper_n_com(X_last_2_word, 380)\n",
    "print('n_com:', X_proper_n_com, 'explained variance ratio:', X_explained_ratio)\n",
    "print('n_com:', X_proper_n_com_last_word, 'explained variance ratio:', X_explained_ratio_last_word)\n",
    "print('n_com:', X_proper_n_com_last_2_word, 'explained variance ratio:', X_explained_ratio_last_2_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no word limit (29774, 508)\n",
      "last word (29774, 109)\n",
      "last 2 word (29774, 384)\n"
     ]
    }
   ],
   "source": [
    "print('no word limit', X_pca.shape)\n",
    "print('last word', X_pca_last_word.shape)\n",
    "print('last 2 word', X_pca_last_2_word.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label encorder for one hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "# Y_le = labelencoder.fit_transform(Y)\n",
    "# Y_le_last_word = labelencoder.fit_transform(Y_last_word)\n",
    "# Y_le_last_2_word = labelencoder.fit_transform(Y_last_2_word)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "Y_le_model = label_encoder.fit(Y)\n",
    "Y_le = Y_le_model.transform(Y)\n",
    "label_encoder_last_word = LabelEncoder()\n",
    "Y_le_model_last_word = label_encoder_last_word.fit(Y_last_word)\n",
    "Y_le_last_word = Y_le_model_last_word.transform(Y_last_word)\n",
    "label_encoder_last_2_word = LabelEncoder()\n",
    "Y_le_model_last_2_word = label_encoder_last_2_word.fit(Y_last_2_word)\n",
    "Y_le_last_2_word = Y_le_model_last_2_word.transform(Y_last_2_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one hot encode label for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_onehot = to_categorical(Y_le)\n",
    "Y_onehot_last_word = to_categorical(Y_le_last_word)\n",
    "Y_onehot_last_2_word = to_categorical(Y_le_last_2_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_model = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_linear_model = SVC(kernel = 'linear')\n",
    "svc_poly_model = SVC(kernel = 'poly')\n",
    "svc_rbf_model = SVC(kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import clone_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=3000, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=200, activation='selu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=len(set(Y)), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_last_word = clone_model(model)\n",
    "model_last_word.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_last_2_word = clone_model(model)\n",
    "model_last_2_word.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I use tensorflow as ANN framework\n",
    "* 用relu和selu和linear是因為我認為這是線性關係\n",
    "* 用softmax當作多類別機率\n",
    "* Dropout避免overfitting\n",
    "* loss: 設定 Loss Function, 因為是multiple class，這邊選定 Cross Entropy 作為 Loss Function.\n",
    "* optimizer: 設定訓練時的優化方法, 在深度學習使用 adam (Adam: A Method for Stochastic Optimization) 可以更快收斂, 考慮momentum和隨次數減少learning rate以提高準確率.\n",
    "* metrics: 設定評估模型的方式是 accuracy 準確率."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "x_train_last_word, x_val_last_word, y_train_last_word, y_val_last_word = train_test_split(X_last_word, Y_last_word, test_size=0.3, random_state=0)\n",
    "x_train_last_2_word, x_val_last_2_word, y_train_last_2_word, y_val_last_2_word = train_test_split(X_last_2_word, Y_last_2_word, test_size=0.3, random_state=0)\n",
    "\n",
    "x_train_pca, x_val_pca, y_train_pca, y_val_pca = train_test_split(X_pca, Y, test_size=0.3, random_state=0)\n",
    "x_train_pca_last_word, x_val_pca_last_word, y_train_pca_last_word, y_val_pca_last_word = train_test_split(X_pca_last_word, Y_last_word, test_size=0.3, random_state=0)\n",
    "x_train_pca_last_2_word, x_val_pca_last_2_word, y_train_pca_last_2_word, y_val_pca_last_2_word = train_test_split(X_pca_last_2_word, Y_last_2_word, test_size=0.3, random_state=0)\n",
    "\n",
    "x_train_onehot, x_val_onehot, y_train_onehot, y_val_onehot = train_test_split(X, Y_onehot, test_size=0.3, random_state=0)\n",
    "x_train_onehot_last_word, x_val_onehot_last_word, y_train_onehot_last_word, y_val_onehot_last_word = train_test_split(X_last_word, Y_onehot_last_word, test_size=0.3, random_state=0)\n",
    "x_train_onehot_last_2_word, x_val_onehot_last_2_word, y_train_onehot_last_2_word, y_val_onehot_last_2_word = train_test_split(X_last_2_word, Y_onehot_last_2_word, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc = linear_svc_model.fit(x_train, y_train)\n",
    "pred_linear_svc = linear_svc.predict(x_val)\n",
    "\n",
    "linear_svc_last_word = linear_svc_model.fit(x_train_last_word, y_train_last_word)\n",
    "pred_linear_svc_last_word = linear_svc_last_word.predict(x_val_last_word)\n",
    "\n",
    "linear_svc_last_2_word = linear_svc_model.fit(x_train_last_2_word, y_train_last_2_word)\n",
    "pred_linear_svc_last_2_word = linear_svc_last_2_word.predict(x_val_last_2_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_linear = svc_linear_model.fit(x_train_pca, y_train_pca)\n",
    "pred_svc_linear = svc_linear.predict(x_val_pca)\n",
    "\n",
    "svc_linear_last_word = svc_linear_model.fit(x_train_pca_last_word, y_train_pca_last_word)\n",
    "pred_svc_linear_last_word = svc_linear_last_word.predict(x_val_pca_last_word)\n",
    "\n",
    "svc_linear_last_2_word = svc_linear_model.fit(x_train_pca_last_2_word, y_train_pca_last_2_word)\n",
    "pred_svc_linear_last_2_word = svc_linear_last_2_word.predict(x_val_pca_last_2_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_poly = svc_poly_model.fit(x_train_pca, y_train_pca)\n",
    "pred_svc_poly = svc_poly.predict(x_val_pca)\n",
    "\n",
    "svc_poly_last_word = svc_poly_model.fit(x_train_pca_last_word, y_train_pca_last_word)\n",
    "pred_svc_poly_last_word = svc_poly_last_word.predict(x_val_pca_last_word)\n",
    "\n",
    "svc_poly_last_2_word = svc_poly_model.fit(x_train_pca_last_2_word, y_train_pca_last_2_word)\n",
    "pred_svc_poly_last_2_word = svc_poly.predict(x_val_pca_last_2_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_rbf = svc_rbf_model.fit(x_train_pca, y_train_pca)\n",
    "pred_svc_rbf = svc_rbf.predict(x_val_pca)\n",
    "\n",
    "svc_rbf_last_word = svc_rbf_model.fit(x_train_pca_last_word, y_train_pca_last_word)\n",
    "pred_svc_rbf_last_word = svc_rbf.predict(x_val_pca_last_word)\n",
    "\n",
    "svc_rbf_last_2_word = svc_rbf_model.fit(x_train_pca_last_2_word, y_train_pca_last_2_word)\n",
    "pred_svc_rbf_last_2_word = svc_rbf_last_2_word.predict(x_val_pca_last_2_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no word limit\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4075: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/8\n",
      "20841/20841 - 1s - loss: 1.9363 - acc: 0.4826\n",
      "Epoch 2/8\n",
      "20841/20841 - 1s - loss: 0.8872 - acc: 0.7543\n",
      "Epoch 3/8\n",
      "20841/20841 - 1s - loss: 0.5140 - acc: 0.8566\n",
      "Epoch 4/8\n",
      "20841/20841 - 1s - loss: 0.3147 - acc: 0.9123\n",
      "Epoch 5/8\n",
      "20841/20841 - 1s - loss: 0.1967 - acc: 0.9504\n",
      "Epoch 6/8\n",
      "20841/20841 - 1s - loss: 0.1231 - acc: 0.9714\n",
      "Epoch 7/8\n",
      "20841/20841 - 1s - loss: 0.0778 - acc: 0.9844\n",
      "Epoch 8/8\n",
      "20841/20841 - 1s - loss: 0.0514 - acc: 0.9916\n",
      "last word\n",
      "Epoch 1/8\n",
      "20841/20841 - 0s - loss: 1.9636 - acc: 0.4535\n",
      "Epoch 2/8\n",
      "20841/20841 - 0s - loss: 1.1143 - acc: 0.6761\n",
      "Epoch 3/8\n",
      "20841/20841 - 0s - loss: 0.8576 - acc: 0.7493\n",
      "Epoch 4/8\n",
      "20841/20841 - 0s - loss: 0.7138 - acc: 0.7882\n",
      "Epoch 5/8\n",
      "20841/20841 - 0s - loss: 0.6114 - acc: 0.8200\n",
      "Epoch 6/8\n",
      "20841/20841 - 0s - loss: 0.5157 - acc: 0.8492\n",
      "Epoch 7/8\n",
      "20841/20841 - 0s - loss: 0.4352 - acc: 0.8725\n",
      "Epoch 8/8\n",
      "20841/20841 - 0s - loss: 0.3645 - acc: 0.8971\n",
      "last 2 word\n",
      "Epoch 1/8\n",
      "20841/20841 - 1s - loss: 1.8676 - acc: 0.4891\n",
      "Epoch 2/8\n",
      "20841/20841 - 1s - loss: 0.8828 - acc: 0.7530\n",
      "Epoch 3/8\n",
      "20841/20841 - 1s - loss: 0.5491 - acc: 0.8425\n",
      "Epoch 4/8\n",
      "20841/20841 - 1s - loss: 0.3644 - acc: 0.8983\n",
      "Epoch 5/8\n",
      "20841/20841 - 1s - loss: 0.2463 - acc: 0.9334\n",
      "Epoch 6/8\n",
      "20841/20841 - 1s - loss: 0.1607 - acc: 0.9595\n",
      "Epoch 7/8\n",
      "20841/20841 - 1s - loss: 0.1074 - acc: 0.9759\n",
      "Epoch 8/8\n",
      "20841/20841 - 1s - loss: 0.0750 - acc: 0.9842\n"
     ]
    }
   ],
   "source": [
    "print('no word limit')\n",
    "train_model = model.fit(x=x_train_onehot, y=y_train_onehot, epochs=8, batch_size=1024, verbose=2)\n",
    "pred_ANN = model.predict_classes(x_val_onehot)\n",
    "print('last word')\n",
    "train_model_last_word = model_last_word.fit(x=x_train_onehot_last_word, y=y_train_onehot_last_word, epochs=8, batch_size=1024, verbose=2)\n",
    "pred_ANN_last_word = model_last_word.predict_classes(x_val_onehot_last_word)\n",
    "print('last 2 word')\n",
    "train_model_last_2_word = model_last_2_word.fit(x=x_train_onehot_last_2_word, y=y_train_onehot_last_2_word, epochs=8, batch_size=1024, verbose=2)\n",
    "pred_ANN_last_2_word = model_last_2_word.predict_classes(x_val_onehot_last_2_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no word limit\n",
      "\tConfusion matrix\n",
      "\t\tlinear_svc: [[  55    1    4    0    5    0    0    4    1    5    0    1    0   10\n",
      "     0    0    6    6    4    0]\n",
      " [   0   74    2    7    1   19    1    4   10   10    2    1    1    5\n",
      "     1    5   22    2    0    4]\n",
      " [   2    1  257    1    0   16    1    4    0   19    1    0    1    8\n",
      "     0    3   44    7    1    1]\n",
      " [   1    0    5  466   14    3    2    4    0    8    1   17   17    5\n",
      "     0    4   12    2   12    8]\n",
      " [   1    0    1   21  103    5    0    5    1   10    3    2    1    8\n",
      "     0    2   12    1    8    5]\n",
      " [   6   12   10    4    3  327    5    4   11  118    1    2    0    6\n",
      "     6    3   43   21    1    4]\n",
      " [   0    3    0    1    2    6  188    9    1   38    0    0    0    2\n",
      "     3    1    8    4    0    0]\n",
      " [   0    0    0    4    3   11    3  577    3   10    2    6    1    8\n",
      "    21    0   10    1    7    3]\n",
      " [   1   25    3    1    0   12    1    5   67   15    2    1    0    3\n",
      "     3    4   23    1    0    0]\n",
      " [   2    8   10    8    3   85   27    5    7 1529    2    3    2   26\n",
      "     8    6   27   20    0    1]\n",
      " [   0    1    0    2    2    6    0    2    1    2   68    0    0    5\n",
      "     0    2    7    3    1    1]\n",
      " [   1    0    5   31    3    4    2   23    2    2    0  230    9    4\n",
      "     0    1    7    0    8    2]\n",
      " [   0    2    2   17    0    4    0    0    0    2    0    9  142    1\n",
      "     2    0    0    1    0    5]\n",
      " [   4    3    6    2    7   20    6    5    1   35    2    3    0 1317\n",
      "     2    2   40   13    3    3]\n",
      " [   0    3    1    0    0    2    4   11    0    9    1    2    0    2\n",
      "   141    0    5    7    2    0]\n",
      " [   0    6    1    1    3   13    0    6    4   16    0    0    0    2\n",
      "     2   44   12    3    0    0]\n",
      " [   5   14   49    7    5   43    4    9    7   36    4    6    2   22\n",
      "     5    8  744    7    1    3]\n",
      " [   8    3    1    0    0   24    5    3    1   32    0    0    1   25\n",
      "     4    1    7   95    1    0]\n",
      " [   0    0    0   17    3    1    0   13    0    0    0    4    4   10\n",
      "     2    0    3    1  206   32]\n",
      " [   3    0    0   15    4    1    1    2    0    5    1    4    2    4\n",
      "     1    0    1    1   34   86]]\n",
      "\t\tsvc_linear: [[  35    1    3    3    4    0    0    3    0    9    0    0    0   12\n",
      "     2    2   18    5    5    0]\n",
      " [   1   48    1    1    2   31    1    5   12   14    1    2    1    5\n",
      "     1    2   39    4    0    0]\n",
      " [   0    2  247    1    0   19    0    3    0   24    0    0    0   10\n",
      "     1    0   52    8    0    0]\n",
      " [   0    2    1  468   13    5    0    1    0    9    1   26   16    7\n",
      "     0    1   11    0   12    8]\n",
      " [   2    2    0   25  101    6    1    2    0   12    0    4    1    6\n",
      "     0    0   13    1    7    6]\n",
      " [   0   10    6    4    4  313    4    2   13  145    0    0    0   10\n",
      "     3    3   59   11    0    0]\n",
      " [   1    1    0    0    0   10  172    3    0   57    1    0    0    2\n",
      "     6    1    9    3    0    0]\n",
      " [   3    4    1    2    4    3    5  566    1   17    2    5    1   12\n",
      "    18    2    9    1   14    0]\n",
      " [   0   27    1    1    1   30    1    1   43   21    1    0    0    4\n",
      "     0    3   30    3    0    0]\n",
      " [   0    9   13    1    4  112   27    6    4 1501    1    4    0   19\n",
      "     4    5   54   14    0    1]\n",
      " [   1    0    3    3    5    6    0    5    0    4   48    1    1   11\n",
      "     0    2   12    1    0    0]\n",
      " [   1    0    0   49    3    7    0   21    2   15    0  200   13    5\n",
      "     0    1   10    0    4    3]\n",
      " [   0    0    0   22    3    3    0    0    0    6    0   17  130    2\n",
      "     1    2    1    0    0    0]\n",
      " [   4    2    4    5    7   24    8   16    3   44    1    1    0 1272\n",
      "     5    4   58   14    1    1]\n",
      " [   0    1    0    0    1    4    3   19    0   14    2    0    0    6\n",
      "   131    1    4    3    0    1]\n",
      " [   0    4    3    0    3   22    2    0    4   16    1    1    0    2\n",
      "     3   35   17    0    0    0]\n",
      " [   7    8   41    3    7   48    9    8   12   71    5    4    1   21\n",
      "     4    7  719    4    2    0]\n",
      " [   5    1    6    0    0   29    7    3    2   52    0    3    0   20\n",
      "     5    0    9   68    1    0]\n",
      " [   2    0    0   25    4    1    0   15    0    0    0    6    2    6\n",
      "     0    0    8    0  200   27]\n",
      " [   2    0    0   21    5    0    0    3    0    6    0    3    2    5\n",
      "     0    0    5    0   32   81]]\n",
      "\t\tsvc_poly: [[   3    0    0    0    1    1    0    2    0   62    0    0    0   22\n",
      "     0    0    9    0    2    0]\n",
      " [   0   10    0    0    0   12    0    0    2   86    0    0    0    1\n",
      "     0    0   60    0    0    0]\n",
      " [   0    0  145    0    0   12    0    0    0  138    0    0    0   22\n",
      "     0    0   49    1    0    0]\n",
      " [   0    0    1  397    0    3    0    2    0  143    0    6    9    8\n",
      "     0    0    8    0    1    3]\n",
      " [   0    0    0   21   61    1    0    2    0   82    0    1    0    9\n",
      "     0    0   10    0    2    0]\n",
      " [   0    1    5    1    1  129    0    0    1  394    0    0    0    2\n",
      "     0    0   50    3    0    0]\n",
      " [   0    0    0    0    0    1   62    1    0  185    0    0    0    5\n",
      "     0    0   11    1    0    0]\n",
      " [   0    1    0    1    2    1    1  421    0  181    0    0    0   43\n",
      "     6    0   12    0    1    0]\n",
      " [   0    4    0    0    0    5    0    0   14   93    0    0    0    1\n",
      "     0    1   49    0    0    0]\n",
      " [   0    0    2    1    2   26    1    1    1 1699    0    0    0   10\n",
      "     0    0   35    1    0    0]\n",
      " [   0    0    0    1    0    1    0    2    0   47   21    0    0   13\n",
      "     0    0   18    0    0    0]\n",
      " [   0    1    0   37    2    0    0   20    0  137    0  113    6    4\n",
      "     0    0   14    0    0    0]\n",
      " [   0    0    0   33    2    0    0    0    0   64    0   10   74    3\n",
      "     0    0    0    0    0    1]\n",
      " [   0    0    2    0    1   11    0    1    1  257    0    0    0 1161\n",
      "     2    1   36    1    0    0]\n",
      " [   0    0    0    0    1    0    0   13    0   86    0    0    0   20\n",
      "    68    0    2    0    0    0]\n",
      " [   0    2    0    0    2   12    0    0    1   58    0    0    0    2\n",
      "     0    9   27    0    0    0]\n",
      " [   0    1   16    0    0   22    0    3    2  345    0    0    0   21\n",
      "     0    0  570    1    0    0]\n",
      " [   0    0    0    0    0    9    1    1    0  159    0    0    0   19\n",
      "     1    0    4   17    0    0]\n",
      " [   0    0    0   26    0    0    0    9    0   74    0    1    2   32\n",
      "     0    0    4    0  137   11]\n",
      " [   0    0    0   19    0    0    0    0    0   53    0    1    0    9\n",
      "     0    0    2    0   33   48]]\n",
      "\t\tsvc_rbf: [[  20    0    2    0    4    0    0    5    0   16    0    0    0   22\n",
      "     3    2   21    2    5    0]\n",
      " [   0   29    1    1    1   38    1    4    3   17    0    0    0    5\n",
      "     0    2   67    2    0    0]\n",
      " [   0    1  245    2    0   20    0    2    0   31    0    0    0   14\n",
      "     1    0   50    1    0    0]\n",
      " [   0    1    0  494    5    5    0    2    0   14    0   11   11    9\n",
      "     0    0   20    0    5    4]\n",
      " [   2    1    0   27   88    5    0    2    0   15    0    1    1    7\n",
      "     0    0   24    0   14    2]\n",
      " [   0    3    6    3    1  300    0    0    6  195    0    0    0    4\n",
      "     0    0   64    5    0    0]\n",
      " [   0    0    1    0    0    5  144    3    0   92    0    0    0    3\n",
      "     2    0   16    0    0    0]\n",
      " [   0    1    1    4    0    6    1  583    0   20    1    1    0   15\n",
      "     9    0   17    0    9    2]\n",
      " [   0   18    0    0    0   34    1    0   34   26    1    0    0    1\n",
      "     0    2   50    0    0    0]\n",
      " [   0    3    3    2    1   75   16    7    2 1582    0    1    0   16\n",
      "     1    0   68    2    0    0]\n",
      " [   1    1    2    2    2    6    0    7    0    5   42    0    0   10\n",
      "     0    0   23    0    2    0]\n",
      " [   0    0    0   60    2    6    0   24    1   16    0  182    8    8\n",
      "     0    0   22    0    3    2]\n",
      " [   0    1    0   32    2    2    0    0    0    6    0   18  117    3\n",
      "     1    0    5    0    0    0]\n",
      " [   0    0    5    3    1   25    3   13    0   57    0    1    0 1302\n",
      "     5    1   54    3    0    1]\n",
      " [   0    0    0    0    0    4    4   21    0   24    1    0    0   10\n",
      "   117    0    7    2    0    0]\n",
      " [   0    4    0    0    2   20    1    2    1   21    0    0    0    2\n",
      "     1   23   36    0    0    0]\n",
      " [   2    2   40    1    1   32    2    8    6   91    0    3    1   23\n",
      "     1    1  763    1    3    0]\n",
      " [   0    1    3    0    0   19    0    4    1   89    0    1    0   25\n",
      "     3    0   12   52    1    0]\n",
      " [   0    1    0   26    3    1    0   15    0    4    0    2    1    8\n",
      "     0    0    8    0  208   19]\n",
      " [   1    0    0   19    0    1    0    2    0    5    0    2    0    5\n",
      "     1    0    9    0   39   81]]\n",
      "\t\tANN: [[  58    0    3    1    2    0    0    4    1    4    0    0    0   13\n",
      "     0    1    5    7    3    0]\n",
      " [   0   79    2    4    2   17    3    4   11   13    0    0    1    5\n",
      "     0    3   25    2    0    0]\n",
      " [   1    0  261    1    0   17    0    3    0   15    0    0    0   13\n",
      "     0    4   43    8    0    1]\n",
      " [   1    0    5  465   10    3    0    2    0    9    1   21   15    6\n",
      "     1    6    7    3   18    8]\n",
      " [   1    1    0   18  116    5    0    3    0   11    1    3    0    6\n",
      "     0    1    9    2    9    3]\n",
      " [   1   14   10    3    3  325    7    3    8  133    1    2    1   10\n",
      "     3    3   38   20    1    1]\n",
      " [   1    0    0    0    0    7  176    7    0   49    0    0    0    1\n",
      "     6    2    9    8    0    0]\n",
      " [   1    3    0    2    1    8    8  599    0    7    0    2    0    7\n",
      "    20    0    4    1    7    0]\n",
      " [   1   24    1    0    0   22    4    2   66   15    1    0    0    2\n",
      "     0    5   22    2    0    0]\n",
      " [   1    3    3    4    0   70   26    5    5 1572    0    2    0   24\n",
      "     3    3   29   27    0    2]\n",
      " [   2    2    1    0    2    4    1    4    0    2   64    0    0    9\n",
      "     0    2    7    2    1    0]\n",
      " [   1    1    1   31    5    8    0   23    1    2    0  235    8    3\n",
      "     0    1    6    1    3    4]\n",
      " [   0    1    0   22    1    4    1    0    0    2    0   12  130    3\n",
      "     2    0    0    0    0    9]\n",
      " [   4    2    7    0    3   17    3    7    1   32    1    2    0 1322\n",
      "     3    1   38   28    2    1]\n",
      " [   1    0    1    0    0    3    3   12    0    4    0    1    0    2\n",
      "   151    0    4    8    0    0]\n",
      " [   0    5    4    0    1   12    4    1    4   20    0    0    0    2\n",
      "     2   41   14    3    0    0]\n",
      " [   1   13   47    4    5   38    7   10    4   47    6    2    0   24\n",
      "     4    4  747   14    3    1]\n",
      " [   3    2    0    1    0   21    8    3    0   29    0    0    0   22\n",
      "     6    0    4  110    2    0]\n",
      " [   0    0    0   17    1    0    0   15    0    1    1    6    1    5\n",
      "     1    0    3    0  221   24]\n",
      " [   1    0    1   18    5    0    0    3    0    3    0    3    3    3\n",
      "     1    0    2    0   27   95]]\n",
      "\tAccuracy\n",
      "\t\tlinear_svc: 0.7518190977275272\n",
      "\t\tsvc_linear: 0.7139818649949625\n",
      "\t\tsvc_poly: 0.5775215493115414\n",
      "\t\tsvc_rbf: 0.7171163103100862\n",
      "\t\tANN: 0.7649166013657226\n",
      "\tSensitivity(Recall)\n",
      "\t\tlinear_svc: 0.7518190977275272\n",
      "\t\tsvc_linear: 0.7139818649949625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tsvc_poly: 0.5775215493115414\n",
      "\t\tsvc_rbf: 0.7171163103100862\n",
      "\t\tANN: 0.7649166013657226\n",
      "\tPrecision\n",
      "\t\tlinear_svc: 0.7482292692149584\n",
      "\t\tsvc_linear: 0.7100263550577157\n",
      "\t\tsvc_poly: 0.6861533023185841\n",
      "\t\tsvc_rbf: 0.7274333486501594\n",
      "\t\tANN: 0.7627224902561239\n",
      "last word\n",
      "\tConfusion matrix\n",
      "\t\tlinear_svc: [[  36    1    6    2    2    3    1    3    1   14    3    1    1   15\n",
      "     0    1    5    1    6    0]\n",
      " [   0   60    2    4    2   25    1    2   10   19    0    1    0    2\n",
      "     0    4   30    2    1    0]\n",
      " [   2    2  218    1    1   15    4    2    2   43    1    0    0   10\n",
      "     1    4   40    3    0    0]\n",
      " [   0    2    1  467    7    6    0    7    0   22    2   13   15   11\n",
      "     2    1    8    2   13    8]\n",
      " [   1    0    3   17   71    9    0    6    0   10    3    4    3    8\n",
      "     0    1   11    2   11    4]\n",
      " [   3   14    4    7    1  329    9    3    7  140    4    2    2   10\n",
      "     3    7   55    8    3    2]\n",
      " [   0    1    3    1    0    5  155    5    0   61    1    0    0    5\n",
      "     3    1    5    0    1    0]\n",
      " [   1    3    6   10    4    5    1  588    2   15    3    4    1   21\n",
      "    20    3   10    2    9    3]\n",
      " [   0   12    0    1    2   20    4    3   56    9    1    2    0    2\n",
      "     1    0   34    1    0    0]\n",
      " [   1    6   16   10    4   88   21    1    3 1478    4    4    4   28\n",
      "     6    2   51   14    7    1]\n",
      " [   1    2    2    2    2    4    0    3    3    4   66    1    0    5\n",
      "     0    0   14    0    0    1]\n",
      " [   0    1    1   41    1    4    0   25    0   12    2  189    7    6\n",
      "     0    1    9    1    5    1]\n",
      " [   0    0    0   34    2    6    0    0    0    2    2    9  129    5\n",
      "     2    0    2    1    4    2]\n",
      " [   2    3    7    3    4   20    5   12    0   47    1    2    3 1329\n",
      "     3    3   31    9    5    2]\n",
      " [   1    2    0    1    0    2    4   13    1   10    2    0    0    8\n",
      "   120    0    3    2    1    1]\n",
      " [   2    2    2    0    1   17    0    3    4   22    0    0    2    4\n",
      "     2   46   13    1    0    1]\n",
      " [   1   16   51    8    9   30    3   12   15   53    5    4    2   41\n",
      "     1    9  716    9    6    1]\n",
      " [   0    2    4    2    2   19    7    8    0   55    1    0    0   15\n",
      "     4    0   12   84    1    0]\n",
      " [   2    0    0   31    3    4    2   14    0    9    1    7    3   10\n",
      "     1    0    2    1  211   14]\n",
      " [   0    2    0   33    9    2    0    2    0    7    1    3    3    6\n",
      "     1    0    1    0   33   72]]\n",
      "\t\tsvc_linear: [[  15    0    5    1    1    4    0    6    0   21    1    0    1   21\n",
      "     0    1   20    1    4    0]\n",
      " [   0   20    1    2    2   33    1    2    5   31    0    0    0    3\n",
      "     0    2   61    2    0    0]\n",
      " [   2    4  214    2    0   18    0    2    0   41    2    0    1    9\n",
      "     2    0   50    1    1    0]\n",
      " [   1    0    3  446   13    7    0    5    0   27    0   20   20    8\n",
      "     0    1   14    0   11   11]\n",
      " [   1    0    1   29   60    9    0    4    0   18    0    1    2    6\n",
      "     0    1   19    2    7    4]\n",
      " [   2    1    3    7    2  276    6    1    3  212    1    1    0    5\n",
      "     4    2   82    5    0    0]\n",
      " [   0    0    3    2    1    2   96    5    0  111    1    0    0    7\n",
      "     5    1   10    3    0    0]\n",
      " [   2    1    5   10    2    4    6  573    0   22    0    4    0   26\n",
      "    19    1   24    3    8    1]\n",
      " [   0   12    0    0    1   23    0    1   31   19    0    2    1    2\n",
      "     1    2   52    1    0    0]\n",
      " [   0    3   33    5    7  106   16    2    3 1441    2    3    2   24\n",
      "     3    2   88    7    2    0]\n",
      " [   1    0    1    3    2    5    0    4    1    6   50    2    2    6\n",
      "     0    0   24    0    3    0]\n",
      " [   0    1    0   56    5    9    0   30    0   11    0  162    9    5\n",
      "     0    1   11    1    3    2]\n",
      " [   0    0    0   54    2    4    0    0    0    6    0   19  104    3\n",
      "     0    3    2    1    2    0]\n",
      " [   4    0    7   10    2   15    2   16    0   92    3    2    2 1263\n",
      "     6    0   51   11    4    1]\n",
      " [   0    0    1    1    0    3    5   20    0   16    1    0    0    4\n",
      "   113    0    4    3    0    0]\n",
      " [   0    8    0    1    2   23    2    3    5   24    0    2    1    5\n",
      "     1   24   19    2    0    0]\n",
      " [   0   10   49   18    6   55    3    5    1  120    4    7    0   41\n",
      "     6    4  653    6    4    0]\n",
      " [   0    3    7    2    0   21   15    4    0   74    2    0    0   14\n",
      "     1    0   16   57    0    0]\n",
      " [   4    0    0   36    3    3    0   15    0   12    0    6    1    4\n",
      "     1    0    7    1  203   19]\n",
      " [   1    0    0   37   13    3    1    5    1    7    0    8    3    3\n",
      "     0    0    4    0   29   60]]\n",
      "\t\tsvc_poly: [[  24    0    6    2    1    3    1    3    0   28    0    0    1   14\n",
      "     0    1   17    0    1    0]\n",
      " [   0   26    0    0    1   14    0    0    4   58    0    1    0    0\n",
      "     0    1   60    0    0    0]\n",
      " [   0    2  188    3    0   15    0    1    0   64    0    0    0   11\n",
      "     0    1   61    3    0    0]\n",
      " [   0    0    1  443    6    2    0    6    0   67    0   10   10    9\n",
      "     0    1   22    0    5    5]\n",
      " [   0    2    0   25   53    5    0    6    0   32    0    1    1   11\n",
      "     0    0   21    1    6    0]\n",
      " [   0    4    2    5    0  234    3    1    1  275    0    0    0    6\n",
      "     2    2   74    2    2    0]\n",
      " [   0    0    1    0    1    1   78    3    0  141    0    0    0    9\n",
      "     0    0   11    1    1    0]\n",
      " [   1    2    1    9    0    3    3  534    0   72    0    2    0   38\n",
      "     9    0   32    0    5    0]\n",
      " [   0    7    0    1    1   12    0    1   38   34    0    0    0    2\n",
      "     0    1   51    0    0    0]\n",
      " [   0    2    4    2    3   59    5    1    1 1573    0    0    1   18\n",
      "     0    2   70    7    0    1]\n",
      " [   0    1    2    4    2    2    0    1    1   21   50    0    0    9\n",
      "     0    0   14    0    3    0]\n",
      " [   0    0    0   57    0    5    0   22    0   40    0  151    4    6\n",
      "     0    0   18    0    2    1]\n",
      " [   0    0    0   59    1    1    0    1    0   22    0   12   84    2\n",
      "     0    1   15    0    2    0]\n",
      " [   3    0    5    5    0   12    0    9    0  161    1    0    0 1237\n",
      "     2    1   51    3    1    0]\n",
      " [   0    0    0    1    0    0    6   16    0   32    0    0    0   12\n",
      "    92    0   11    1    0    0]\n",
      " [   0    2    1    0    0   16    2    2    6   39    0    0    1    5\n",
      "     1   21   23    3    0    0]\n",
      " [   0    4   28    6    1   39    0    3    2  196    2    3    0   30\n",
      "     2    0  671    2    3    0]\n",
      " [   0    0    3    1    0   13    2    4    0  124    0    0    0   10\n",
      "     0    0   12   47    0    0]\n",
      " [   0    0    1   37    1    1    0   16    0   25    0    3    1   12\n",
      "     0    0    5    0  200   13]\n",
      " [   0    0    0   42    2    1    0    3    0   30    0    1    1    8\n",
      "     0    0    8    0   19   60]]\n",
      "\t\tsvc_rbf: [[  25    1    5    2    1    3    1    6    0   21    0    0    1   14\n",
      "     0    1   19    0    2    0]\n",
      " [   0   36    0    1    0   24    1    2    6   39    0    0    0    0\n",
      "     0    2   53    1    0    0]\n",
      " [   0    1  222    2    0   19    0    3    0   36    0    0    0   10\n",
      "     0    0   51    4    1    0]\n",
      " [   0    0    1  475    7    6    0    7    0   30    0    9   10    8\n",
      "     0    0   17    0    9    8]\n",
      " [   0    0    0   31   61    7    0    6    0   19    0    1    1    6\n",
      "     0    0   22    2    7    1]\n",
      " [   0    5    4    5    0  280    3    1    0  223    0    0    0    5\n",
      "     2    1   78    4    2    0]\n",
      " [   0    0    3    2    2    2   97    3    0  112    0    0    0   10\n",
      "     1    0   13    1    1    0]\n",
      " [   1    2    4    8    1    2    2  591    0   23    0    0    0   30\n",
      "    12    0   25    1    8    1]\n",
      " [   0   13    0    2    1   25    0    3   37   22    0    0    0    2\n",
      "     0    1   42    0    0    0]\n",
      " [   0    2   19    4    4   75   10    5    1 1507    0    0    1   19\n",
      "     1    2   88    5    5    1]\n",
      " [   1    1    2    2    0    3    0    1    1    5   55    1    0    6\n",
      "     0    0   27    0    3    2]\n",
      " [   0    1    0   62    2    6    1   27    0   11    0  160    5    6\n",
      "     0    0   19    0    5    1]\n",
      " [   0    0    0   62    1    0    0    2    0    6    0   14  100    2\n",
      "     0    1    8    0    3    1]\n",
      " [   3    0   11    9    0   15    1   15    0   94    1    2    0 1285\n",
      "     1    0   48    5    0    1]\n",
      " [   0    0    0    1    0    4    4   18    0   11    1    0    0    8\n",
      "   109    0   11    4    0    0]\n",
      " [   0    5    0    0    1   21    3    2    5   31    0    1    1    5\n",
      "     1   22   23    1    0    0]\n",
      " [   0    4   49   13    6   46    3    4    2  110    1    2    1   39\n",
      "     2    2  700    3    5    0]\n",
      " [   0    1    5    1    0   17    9    4    0   88    0    0    0   12\n",
      "     0    0   18   61    0    0]\n",
      " [   0    0    0   29    2    4    0   17    0   12    0    2    4    5\n",
      "     0    0    5    0  221   14]\n",
      " [   0    0    1   33    5    3    1    5    2   13    0    2    2    5\n",
      "     0    0    2    0   30   71]]\n",
      "\t\tANN: [[  49    0    3    3    4    2    1    4    1    7    2    1    0   13\n",
      "     1    1    4    2    4    0]\n",
      " [   2   84    3    2    1   10    2    1   13   12    0    2    0    2\n",
      "     0    1   28    2    0    0]\n",
      " [   1    3  235    0    2   15    2    2    1   27    0    0    0   12\n",
      "     2    1   42    4    0    0]\n",
      " [   0    0    2  473   16    5    0   10    0    6    1   24    9    3\n",
      "     1    0    4    2   23    8]\n",
      " [   1    1    0   15   89    5    0    8    0    1    0    2    2    8\n",
      "     0    1   11    3   14    3]\n",
      " [   2   20    6    8    3  355   14    3   13  102    1    3    1   10\n",
      "     3    4   45   16    2    2]\n",
      " [   0    0    3    1    0    4  173    8    0   44    1    0    0    6\n",
      "     2    1    2    2    0    0]\n",
      " [   2    2    2    7    4    3    1  632    0    5    0    2    1   12\n",
      "    15    0   13    1    9    0]\n",
      " [   0   16    0    2    0   18    7    2   71    6    0    0    0    2\n",
      "     1    0   20    3    0    0]\n",
      " [   1    8   31   10    5  103   40   10    6 1405    3    5    2   34\n",
      "     9    0   47   26    4    0]\n",
      " [   2    1    1    2    2    4    1    5    3    4   68    2    0    5\n",
      "     0    0    7    0    2    1]\n",
      " [   0    2    0   31    4    2    0   26    1    3    0  209    3    6\n",
      "     0    1    9    1    6    2]\n",
      " [   0    1    1   39    4    1    0    0    0    2    0   15  121    6\n",
      "     0    0    1    4    2    3]\n",
      " [   2    3    7    3    4   17    5   27    0   29    2    3    1 1331\n",
      "     4    1   28   21    2    1]\n",
      " [   0    1    0    1    0    2    4   22    1    5    1    0    0    4\n",
      "   125    0    3    2    0    0]\n",
      " [   2    5    4    0    4   14    2    2    5   17    0    1    1    4\n",
      "     1   48   10    1    0    1]\n",
      " [   1   14   55    9   13   31    0    8   10   34    5    4    0   45\n",
      "     3    6  743    7    3    1]\n",
      " [   3    3    7    1    1   19    6    9    1   33    1    1    0   12\n",
      "     3    0   10  105    1    0]\n",
      " [   2    0    0   23    3    1    2   18    0    4    1    6    2    8\n",
      "     0    0    2    1  230   12]\n",
      " [   0    3    1   26   11    0    0    2    0    6    0    7    2    1\n",
      "     1    0    1    1   38   75]]\n",
      "\tAccuracy\n",
      "\t\tlinear_svc: 0.7186835329676481\n",
      "\t\tsvc_linear: 0.6561065711407142\n",
      "\t\tsvc_poly: 0.6497257360349267\n",
      "\t\tsvc_rbf: 0.6845404679279078\n",
      "\t\tANN: 0.7411843725512146\n",
      "\tSensitivity(Recall)\n",
      "\t\tlinear_svc: 0.7186835329676481\n",
      "\t\tsvc_linear: 0.6561065711407142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tsvc_poly: 0.6497257360349267\n",
      "\t\tsvc_rbf: 0.6845404679279078\n",
      "\t\tANN: 0.7411843725512146\n",
      "\tPrecision\n",
      "\t\tlinear_svc: 0.7131890614718477\n",
      "\t\tsvc_linear: 0.6540039402529008\n",
      "\t\tsvc_poly: 0.6872679527735676\n",
      "\t\tsvc_rbf: 0.6972520042246662\n",
      "\t\tANN: 0.7403820188931293\n",
      "last 2 word\n",
      "\tConfusion matrix\n",
      "\t\tlinear_svc: [[  57    1    1    1    1    3    0    2    2    1    3    0    0   13\n",
      "     0    1    5    2    6    0]\n",
      " [   2   87    1    0    0   26    3    7   20   15    1    0    0    4\n",
      "     0    2   32    1    0    0]\n",
      " [   3    5  245    0    0    8    2    4    0   22    2    0    0    9\n",
      "     1    2   60    4    0    0]\n",
      " [   1    0    2  457    8    4    1    5    1   13    1   14   16    9\n",
      "     2    2   13    1   11   15]\n",
      " [   6    0    0   16  107    4    0    4    0    6    2    3    2    8\n",
      "     0    1   11    3    4    1]\n",
      " [   1   10    4    4    3  356    8    7   12  113    5    1    0   11\n",
      "     5    8   31   19    0    1]\n",
      " [   1    1    1    1    0   12  178    7    0   37    0    1    2    1\n",
      "     8    3   10   13    0    2]\n",
      " [   1    2    0    3    3    2    6  579    1    6    1    9    2   13\n",
      "    11    0    5    1   10    0]\n",
      " [   0   12    0    1    0   15    3    5   74    7    0    0    0    3\n",
      "     2    6   16    4    0    0]\n",
      " [   2    3   11    2    4   84   31    9    4 1557    3    2    1   22\n",
      "     3    5   31   23    1    3]\n",
      " [   0    3    4    4    3    1    1   10    0    0   73    1    0    5\n",
      "     2    0    6    1    0    0]\n",
      " [   0    0    1   32    7    5    1   22    1    4    0  222    7    4\n",
      "     1    1    6    2    0    4]\n",
      " [   1    0    0   22    2    1    1    1    1    3    0   12  138    0\n",
      "     1    0    2    0    2    4]\n",
      " [   3    3    9    7   11   12    8    5    7   30    5    2    0 1272\n",
      "     0    1   26    4    6    1]\n",
      " [   0    0    0    1    0    4    6   12    0    9    0    1    0    4\n",
      "   145    1    3    4    1    0]\n",
      " [   4    4    2    1    3   20    4    1   10    6    0    2    1    3\n",
      "     0   45    9    1    0    0]\n",
      " [   4    8   46   12    4   35    4    4   14   38    6    2    2   24\n",
      "     3    9  704    4    3    5]\n",
      " [   3    1    5    1    2   21    5    3    1   44    0    1    0   13\n",
      "     4    1    7   98    1    0]\n",
      " [   1    0    1   21    5    2    0   16    0    2    2    6    5    5\n",
      "     0    0    3    0  234   31]\n",
      " [   1    0    1   26    3    2    0    4    0    3    1    2    6    2\n",
      "     1    0    2    1   42  114]]\n",
      "\t\tsvc_linear: [[  35    1    3    2    4    2    0    1    1   10    3    1    0   21\n",
      "     0    1    7    4    3    0]\n",
      " [   1   48    0    0    0   33    2    5   22   26    0    1    0    3\n",
      "     0    5   53    1    1    0]\n",
      " [   0    5  249    1    0   11    0    3    1   27    2    0    1   10\n",
      "     1    1   54    1    0    0]\n",
      " [   2    3    0  455   13    9    0    2    0   11    1   25   19    7\n",
      "     0    3   12    0    8    6]\n",
      " [   7    2    2   17   96    5    0    2    2    8    1    0    1    8\n",
      "     0    1   15    3    3    5]\n",
      " [   1   11    8    3    4  334    5    0    6  152    1    1    0    8\n",
      "     2    6   46   11    0    0]\n",
      " [   0    0    0    0    2   12  177    5    0   52    0    2    1    8\n",
      "     6    2    6    5    0    0]\n",
      " [   2    4    0    4    4    5    4  567    3    8    2    5    0   12\n",
      "    15    2   12    0    6    0]\n",
      " [   0   19    0    1    0   27    0    1   56    7    0    2    0    4\n",
      "     0    4   27    0    0    0]\n",
      " [   0    5   10    5    3  106   32    5    7 1513    2    2    1   24\n",
      "     4    3   61   16    1    1]\n",
      " [   2    2    2    2    5    2    0   10    1    1   63    0    0    6\n",
      "     1    0   15    0    2    0]\n",
      " [   1    2    0   45   10    7    1   21    1   20    0  182    8    4\n",
      "     0    0   11    2    1    4]\n",
      " [   1    0    0   27    4    1    1    0    0    2    0   21  127    0\n",
      "     0    0    0    0    2    5]\n",
      " [   4    4    3    7    6   18    5   13    2   42    1    2    0 1239\n",
      "     5    2   46   10    3    0]\n",
      " [   1    1    2    0    1    6   14   17    0    8    0    1    0    2\n",
      "   129    2    3    4    0    0]\n",
      " [   1    6    1    3    3   21    1    1    9   14    0    5    0    4\n",
      "     2   32   11    2    0    0]\n",
      " [   5   13   46    6    2   45    3    7   13   64    6    5    0   32\n",
      "     2   10  668    3    1    0]\n",
      " [   3    2    1    0    2   26    6    0    5   57    1    2    0   16\n",
      "     5    1   11   72    1    0]\n",
      " [   2    1    0   25    8    0    0   14    0    4    0    6    1    1\n",
      "     0    0    4    1  234   33]\n",
      " [   4    0    1   28    3    3    1    4    1    1    0    7    4    4\n",
      "     1    1    4    0   46   98]]\n",
      "\t\tsvc_poly: [[   6    0    0    0    1    0    0    1    0   58    0    0    0   18\n",
      "     0    0   12    2    1    0]\n",
      " [   0    9    0    0    0   20    0    2    4   95    0    0    0    1\n",
      "     0    0   70    0    0    0]\n",
      " [   0    0  152    0    0   11    0    2    0  110    0    0    0   20\n",
      "     0    0   71    1    0    0]\n",
      " [   0    0    0  423    1    3    0    0    0   98    0    7   16    7\n",
      "     0    0   14    0    4    3]\n",
      " [   0    0    1   16   58    0    0    0    1   67    0    0    0    9\n",
      "     0    0   22    3    1    0]\n",
      " [   0    0    1    0    0  171    1    1    0  368    0    0    0    4\n",
      "     0    0   51    2    0    0]\n",
      " [   0    0    0    0    0    4   71    2    0  181    0    0    0    7\n",
      "     1    0   10    2    0    0]\n",
      " [   0    1    0    1    1    1    1  463    0  133    1    0    0   35\n",
      "     4    0   11    0    3    0]\n",
      " [   0    1    0    1    0    6    0    0   19   63    0    0    0    1\n",
      "     0    0   57    0    0    0]\n",
      " [   0    0    1    1    0   37    4    0    2 1713    0    0    0   16\n",
      "     0    0   26    1    0    0]\n",
      " [   0    0    0    3    0    0    0    7    0   29   42    0    0   15\n",
      "     1    0   17    0    0    0]\n",
      " [   0    0    0   50    1    2    0   22    1  105    0  121    5    5\n",
      "     0    0    8    0    0    0]\n",
      " [   0    0    0   34    2    1    0    0    0   44    0   10   88    4\n",
      "     0    0    7    0    1    0]\n",
      " [   0    0    4    1    0    8    0    0    0  152    0    0    0 1203\n",
      "     1    0   42    1    0    0]\n",
      " [   0    0    0    0    1    1    2   13    0   77    0    0    0   17\n",
      "    75    0    5    0    0    0]\n",
      " [   0    0    0    0    0   14    1    1    1   54    0    0    0    3\n",
      "     0    7   32    3    0    0]\n",
      " [   0    2   22    3    0   15    0    3    4  293    0    0    0   35\n",
      "     1    2  550    1    0    0]\n",
      " [   0    0    0    0    0    8    0    0    0  158    0    0    0   15\n",
      "     0    0    4   26    0    0]\n",
      " [   0    0    1   33    1    0    0   11    0   48    1    2    1   17\n",
      "     0    0    4    0  206    9]\n",
      " [   0    0    0   27    2    0    0    1    0   60    0    3    2   12\n",
      "     0    0    0    0   38   66]]\n",
      "\t\tsvc_rbf: [[  25    1    3    0    3    3    0    7    0   17    0    0    0   22\n",
      "     0    1   15    1    1    0]\n",
      " [   1   31    0    0    0   44    0    7   13   30    0    0    0    3\n",
      "     0    0   71    0    1    0]\n",
      " [   0    2  253    0    0   14    0    3    0   29    1    0    0   10\n",
      "     1    0   53    1    0    0]\n",
      " [   0    0    0  471    8    9    0    1    0   17    0   16   11    9\n",
      "     0    1   24    0    5    4]\n",
      " [   2    0    1   18   94    5    0    1    1   12    0    0    2    9\n",
      "     0    1   26    2    1    3]\n",
      " [   1    3    3    0    3  314    3    3    2  195    1    0    0    5\n",
      "     1    4   55    6    0    0]\n",
      " [   0    0    0    1    1    8  152    3    0   83    0    1    0    8\n",
      "     4    0   16    1    0    0]\n",
      " [   1    0    0    3    5    4    4  571    0   10    2    4    0   16\n",
      "     9    0   18    1    7    0]\n",
      " [   0    8    1    1    1   27    0    0   38   14    0    1    0    5\n",
      "     0    1   51    0    0    0]\n",
      " [   0    0    6    2    1   72   21    4    2 1590    2    1    0   27\n",
      "     0    0   69    3    1    0]\n",
      " [   1    0    3    2    3    1    0   14    0    2   57    0    0    7\n",
      "     0    0   21    0    3    0]\n",
      " [   0    0    0   55    6   12    0   24    0   22    0  165    7    3\n",
      "     0    0   22    0    3    1]\n",
      " [   0    0    0   37    1    1    1    0    1    5    1   21  113    2\n",
      "     0    0    3    0    1    4]\n",
      " [   0    1    3    5    2   13    2    8    0   44    0    2    0 1279\n",
      "     1    0   48    3    1    0]\n",
      " [   0    0    0    0    2    9    8   19    0   14    0    0    0    6\n",
      "   124    0    7    2    0    0]\n",
      " [   1    0    1    1    1   27    0    2    6   14    0    2    0    4\n",
      "     0   22   31    4    0    0]\n",
      " [   2    4   51    9    0   35    1    7    6   70    2    2    0   27\n",
      "     0    8  702    3    2    0]\n",
      " [   0    0    4    0    0   22    2    2    0   83    0    1    0   17\n",
      "     2    1   12   64    1    0]\n",
      " [   0    0    1   25    1    0    0   13    0    2    0    4    1    2\n",
      "     0    0   11    0  260   14]\n",
      " [   3    0    0   29    1    1    0    1    0    5    0    3    3    9\n",
      "     0    0    7    1   62   86]]\n",
      "\t\tANN: [[  56    1    1    1    0    3    1    2    2    1    4    0    0   11\n",
      "     0    1    6    4    5    0]\n",
      " [   2   98    0    0    1   36    2    5   22    9    1    0    0    3\n",
      "     0    2   20    0    0    0]\n",
      " [   2    8  254    0    2   14    0    2    0   20    0    1    0   12\n",
      "     0    0   50    2    0    0]\n",
      " [   3    4    2  461   11    6    1    4    0    7    0   19   18    5\n",
      "     1    1    7    0   16   10]\n",
      " [   8    0    0   16  114    2    0    2    0    3    2    3    0   10\n",
      "     0    2    5    3    5    3]\n",
      " [   0   15    6    4    1  397    6    5    9   95    1    2    0   12\n",
      "     3    5   22   16    0    0]\n",
      " [   0    0    1    2    0   18  190    9    1   35    0    1    0    3\n",
      "     3    4    6    5    0    0]\n",
      " [   2    1    0    3    2    4    2  601    1    1    2    6    0    5\n",
      "    10    1    5    0    9    0]\n",
      " [   0   26    1    3    0   17    2    1   76    5    0    0    0    2\n",
      "     1    1   12    0    1    0]\n",
      " [   2    7   12    1    2  100   37    3    4 1545    2    2    0   20\n",
      "     3    4   34   22    1    0]\n",
      " [   1    5    2    3    1    1    0    7    1    1   73    1    1    9\n",
      "     1    0    7    0    0    0]\n",
      " [   1    1    0   34    3    5    0   23    1    5    0  230    6    1\n",
      "     0    1    5    0    3    1]\n",
      " [   0    1    0   24    4    0    0    0    0    2    0   17  136    2\n",
      "     0    0    1    0    3    1]\n",
      " [   2    6    9    3    4   11    7    4    0   26    3    4    0 1297\n",
      "     2    1   21    8    4    0]\n",
      " [   0    0    0    0    0    4    8   21    1    5    0    1    0    2\n",
      "   145    1    1    2    0    0]\n",
      " [   1    7    1    0    1   18    2    2    9    7    0    4    0    5\n",
      "     0   51    6    2    0    0]\n",
      " [   4   17   55    8    5   50    1    5   12   33    6    3    0   32\n",
      "     0    8  685    3    3    1]\n",
      " [   0    3    8    3    1   21    7    5    1   36    1    0    0   11\n",
      "     5    3    6   97    2    1]\n",
      " [   1    0    0   14    4    1    1   13    0    1    0    7    3    7\n",
      "     0    0    3    0  265   14]\n",
      " [   3    0    0   23    3    2    0    4    0    2    0    6    7    1\n",
      "     1    0    2    0   61   96]]\n",
      "\tAccuracy\n",
      "\t\tlinear_svc: 0.7547296540915706\n",
      "\t\tsvc_linear: 0.713534087092802\n",
      "\t\tsvc_poly: 0.6122243367289825\n",
      "\t\tsvc_rbf: 0.7176760326877869\n",
      "\t\tANN: 0.768722713534087\n",
      "\tSensitivity(Recall)\n",
      "\t\tlinear_svc: 0.7547296540915706\n",
      "\t\tsvc_linear: 0.713534087092802\n",
      "\t\tsvc_poly: 0.6122243367289825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tsvc_rbf: 0.7176760326877869\n",
      "\t\tANN: 0.768722713534087\n",
      "\tPrecision\n",
      "\t\tlinear_svc: 0.7508727612727286\n",
      "\t\tsvc_linear: 0.7084583473370906\n",
      "\t\tsvc_poly: 0.6938962094997846\n",
      "\t\tsvc_rbf: 0.7222459572669201\n",
      "\t\tANN: 0.768157488243125\n"
     ]
    }
   ],
   "source": [
    "print('no word limit')\n",
    "print('\\tConfusion matrix')\n",
    "print('\\t\\tlinear_svc:', confusion_matrix(y_val, pred_linear_svc))\n",
    "print('\\t\\tsvc_linear:', confusion_matrix(y_val_pca, pred_svc_linear))\n",
    "print('\\t\\tsvc_poly:', confusion_matrix(y_val_pca, pred_svc_poly))\n",
    "print('\\t\\tsvc_rbf:', confusion_matrix(y_val_pca, pred_svc_rbf))\n",
    "print('\\t\\tANN:', confusion_matrix(np.argmax(y_val_onehot, axis=1), pred_ANN))\n",
    "print('\\tAccuracy')\n",
    "print('\\t\\tlinear_svc:', accuracy_score(y_val, pred_linear_svc))\n",
    "print('\\t\\tsvc_linear:', accuracy_score(y_val_pca, pred_svc_linear))\n",
    "print('\\t\\tsvc_poly:', accuracy_score(y_val_pca, pred_svc_poly))\n",
    "print('\\t\\tsvc_rbf:', accuracy_score(y_val_pca, pred_svc_rbf))\n",
    "print('\\t\\tANN:', accuracy_score(np.argmax(y_val_onehot, axis=1), pred_ANN))\n",
    "print('\\tSensitivity(Recall)')\n",
    "print('\\t\\tlinear_svc:', recall_score(y_val, pred_linear_svc, average='weighted'))\n",
    "print('\\t\\tsvc_linear:', recall_score(y_val_pca, pred_svc_linear, average='weighted'))\n",
    "print('\\t\\tsvc_poly:', recall_score(y_val_pca, pred_svc_poly, average='weighted'))\n",
    "print('\\t\\tsvc_rbf:', recall_score(y_val_pca, pred_svc_rbf, average='weighted'))\n",
    "print('\\t\\tANN:', recall_score(np.argmax(y_val_onehot, axis=1), pred_ANN, average='weighted'))\n",
    "print('\\tPrecision')\n",
    "print('\\t\\tlinear_svc:', precision_score(y_val, pred_linear_svc, average='weighted'))\n",
    "print('\\t\\tsvc_linear:', precision_score(y_val_pca, pred_svc_linear, average='weighted'))\n",
    "print('\\t\\tsvc_poly:', precision_score(y_val_pca, pred_svc_poly, average='weighted'))\n",
    "print('\\t\\tsvc_rbf:', precision_score(y_val_pca, pred_svc_rbf, average='weighted'))\n",
    "print('\\t\\tANN:', precision_score(np.argmax(y_val_onehot, axis=1), pred_ANN, average='weighted'))\n",
    "\n",
    "print('last word')\n",
    "print('\\tConfusion matrix')\n",
    "print('\\t\\tlinear_svc:', confusion_matrix(y_val_last_word, pred_linear_svc_last_word))\n",
    "print('\\t\\tsvc_linear:', confusion_matrix(y_val_pca_last_word, pred_svc_linear_last_word))\n",
    "print('\\t\\tsvc_poly:', confusion_matrix(y_val_pca_last_word, pred_svc_poly_last_word))\n",
    "print('\\t\\tsvc_rbf:', confusion_matrix(y_val_pca_last_word, pred_svc_rbf_last_word))\n",
    "print('\\t\\tANN:', confusion_matrix(np.argmax(y_val_onehot_last_word, axis=1), pred_ANN_last_word))\n",
    "print('\\tAccuracy')\n",
    "print('\\t\\tlinear_svc:', accuracy_score(y_val_last_word, pred_linear_svc_last_word))\n",
    "print('\\t\\tsvc_linear:', accuracy_score(y_val_pca_last_word, pred_svc_linear_last_word))\n",
    "print('\\t\\tsvc_poly:', accuracy_score(y_val_pca_last_word, pred_svc_poly_last_word))\n",
    "print('\\t\\tsvc_rbf:', accuracy_score(y_val_pca_last_word, pred_svc_rbf_last_word))\n",
    "print('\\t\\tANN:', accuracy_score(np.argmax(y_val_onehot_last_word, axis=1), pred_ANN_last_word))\n",
    "print('\\tSensitivity(Recall)')\n",
    "print('\\t\\tlinear_svc:', recall_score(y_val_last_word, pred_linear_svc_last_word, average='weighted'))\n",
    "print('\\t\\tsvc_linear:', recall_score(y_val_pca_last_word, pred_svc_linear_last_word, average='weighted'))\n",
    "print('\\t\\tsvc_poly:', recall_score(y_val_pca_last_word, pred_svc_poly_last_word, average='weighted'))\n",
    "print('\\t\\tsvc_rbf:', recall_score(y_val_pca_last_word, pred_svc_rbf_last_word, average='weighted'))\n",
    "print('\\t\\tANN:', recall_score(np.argmax(y_val_onehot_last_word, axis=1), pred_ANN_last_word, average='weighted'))\n",
    "print('\\tPrecision')\n",
    "print('\\t\\tlinear_svc:', precision_score(y_val_last_word, pred_linear_svc_last_word, average='weighted'))\n",
    "print('\\t\\tsvc_linear:', precision_score(y_val_pca_last_word, pred_svc_linear_last_word, average='weighted'))\n",
    "print('\\t\\tsvc_poly:', precision_score(y_val_pca_last_word, pred_svc_poly_last_word, average='weighted'))\n",
    "print('\\t\\tsvc_rbf:', precision_score(y_val_pca_last_word, pred_svc_rbf_last_word, average='weighted'))\n",
    "print('\\t\\tANN:', precision_score(np.argmax(y_val_onehot_last_word, axis=1), pred_ANN_last_word, average='weighted'))\n",
    "\n",
    "print('last 2 word')\n",
    "print('\\tConfusion matrix')\n",
    "print('\\t\\tlinear_svc:', confusion_matrix(y_val_last_2_word, pred_linear_svc_last_2_word))\n",
    "print('\\t\\tsvc_linear:', confusion_matrix(y_val_pca_last_2_word, pred_svc_linear_last_2_word))\n",
    "print('\\t\\tsvc_poly:', confusion_matrix(y_val_pca_last_2_word, pred_svc_poly_last_2_word))\n",
    "print('\\t\\tsvc_rbf:', confusion_matrix(y_val_pca_last_2_word, pred_svc_rbf_last_2_word))\n",
    "print('\\t\\tANN:', confusion_matrix(np.argmax(y_val_onehot_last_2_word, axis=1), pred_ANN_last_2_word))\n",
    "print('\\tAccuracy')\n",
    "print('\\t\\tlinear_svc:', accuracy_score(y_val_last_2_word, pred_linear_svc_last_2_word))\n",
    "print('\\t\\tsvc_linear:', accuracy_score(y_val_pca_last_2_word, pred_svc_linear_last_2_word))\n",
    "print('\\t\\tsvc_poly:', accuracy_score(y_val_pca_last_2_word, pred_svc_poly_last_2_word))\n",
    "print('\\t\\tsvc_rbf:', accuracy_score(y_val_pca_last_2_word, pred_svc_rbf_last_2_word))\n",
    "print('\\t\\tANN:', accuracy_score(np.argmax(y_val_onehot_last_2_word, axis=1), pred_ANN_last_2_word))\n",
    "print('\\tSensitivity(Recall)')\n",
    "print('\\t\\tlinear_svc:', recall_score(y_val_last_2_word, pred_linear_svc_last_2_word, average='weighted'))\n",
    "print('\\t\\tsvc_linear:', recall_score(y_val_pca_last_2_word, pred_svc_linear_last_2_word, average='weighted'))\n",
    "print('\\t\\tsvc_poly:', recall_score(y_val_pca_last_2_word, pred_svc_poly_last_2_word, average='weighted'))\n",
    "print('\\t\\tsvc_rbf:', recall_score(y_val_pca_last_2_word, pred_svc_rbf_last_2_word, average='weighted'))\n",
    "print('\\t\\tANN:', recall_score(np.argmax(y_val_onehot_last_2_word, axis=1), pred_ANN_last_2_word, average='weighted'))\n",
    "print('\\tPrecision')\n",
    "print('\\t\\tlinear_svc:', precision_score(y_val_last_2_word, pred_linear_svc_last_2_word, average='weighted'))\n",
    "print('\\t\\tsvc_linear:', precision_score(y_val_pca_last_2_word, pred_svc_linear_last_2_word, average='weighted'))\n",
    "print('\\t\\tsvc_poly:', precision_score(y_val_pca_last_2_word, pred_svc_poly_last_2_word, average='weighted'))\n",
    "print('\\t\\tsvc_rbf:', precision_score(y_val_pca_last_2_word, pred_svc_rbf_last_2_word, average='weighted'))\n",
    "print('\\t\\tANN:', precision_score(np.argmax(y_val_onehot_last_2_word, axis=1), pred_ANN_last_2_word, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "\tno word limit\t\t\t\tlast word\t\t\t\tlast 2 word\n",
      "\tlinear_svc: 0.7518190977275272 \t\t 0.7186835329676481 \t\t 0.7547296540915706\n",
      "\tsvc_linear: 0.7139818649949625 \t\t 0.6561065711407142 \t\t 0.713534087092802\n",
      "\tsvc_poly: 0.5775215493115414 \t\t 0.6497257360349267 \t\t 0.6122243367289825\n",
      "\tsvc_rbf: 0.7171163103100862 \t\t 0.6845404679279078 \t\t 0.7176760326877869\n",
      "\tANN: 0.7649166013657226 \t\t 0.7411843725512146 \t\t 0.768722713534087\n",
      "Sensitivity(Recall)\n",
      "\tno word limit\t\t\t\tlast word\t\t\t\tlast 2 word\n",
      "\tlinear_svc: 0.7518190977275272 \t\t 0.7186835329676481 \t\t 0.7547296540915706\n",
      "\tsvc_linear: 0.7139818649949625 \t\t 0.6561065711407142 \t\t 0.713534087092802\n",
      "\tsvc_poly: 0.5775215493115414 \t\t 0.6497257360349267 \t\t 0.6122243367289825\n",
      "\tsvc_rbf: 0.7171163103100862 \t\t 0.6845404679279078 \t\t 0.7176760326877869\n",
      "\tANN: 0.7649166013657226 \t\t 0.7411843725512146 \t\t 0.768722713534087\n",
      "Precision\n",
      "\tno word limit\t\t\t\tlast word\t\t\t\tlast 2 word\n",
      "\tlinear_svc: 0.7482292692149584 \t\t 0.7131890614718477 \t\t 0.7508727612727286\n",
      "\tsvc_linear: 0.7100263550577157 \t\t 0.6540039402529008 \t\t 0.7084583473370906\n",
      "\tsvc_poly: 0.6861533023185841 \t\t 0.6872679527735676 \t\t 0.6938962094997846\n",
      "\tsvc_rbf: 0.7274333486501594 \t\t 0.6972520042246662 \t\t 0.7222459572669201\n",
      "\tANN: 0.7627224902561239 \t\t 0.7403820188931293 \t\t 0.768157488243125\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy')\n",
    "print('\\tno word limit', 'last word', 'last 2 word', sep='\\t\\t\\t\\t')\n",
    "print('\\tlinear_svc:', accuracy_score(y_val, pred_linear_svc),'\\t\\t', accuracy_score(y_val_last_word, pred_linear_svc_last_word), '\\t\\t', accuracy_score(y_val_last_2_word, pred_linear_svc_last_2_word))\n",
    "print('\\tsvc_linear:', accuracy_score(y_val_pca, pred_svc_linear),'\\t\\t', accuracy_score(y_val_pca_last_word, pred_svc_linear_last_word), '\\t\\t', accuracy_score(y_val_pca_last_2_word, pred_svc_linear_last_2_word))\n",
    "print('\\tsvc_poly:', accuracy_score(y_val_pca, pred_svc_poly),'\\t\\t', accuracy_score(y_val_pca_last_word, pred_svc_poly_last_word),'\\t\\t', accuracy_score(y_val_pca_last_2_word, pred_svc_poly_last_2_word))\n",
    "print('\\tsvc_rbf:', accuracy_score(y_val_pca, pred_svc_rbf),'\\t\\t', accuracy_score(y_val_pca_last_word, pred_svc_rbf_last_word),'\\t\\t', accuracy_score(y_val_pca_last_2_word, pred_svc_rbf_last_2_word))\n",
    "print('\\tANN:', accuracy_score(np.argmax(y_val_onehot, axis=1), pred_ANN),'\\t\\t', accuracy_score(np.argmax(y_val_onehot_last_word, axis=1), pred_ANN_last_word),'\\t\\t', accuracy_score(np.argmax(y_val_onehot_last_2_word, axis=1), pred_ANN_last_2_word))\n",
    "\n",
    "print('Sensitivity(Recall)')\n",
    "print('\\tno word limit', 'last word', 'last 2 word', sep='\\t\\t\\t\\t')\n",
    "print('\\tlinear_svc:', recall_score(y_val, pred_linear_svc, average='weighted'),'\\t\\t', recall_score(y_val_last_word, pred_linear_svc_last_word, average='weighted'), '\\t\\t', recall_score(y_val_last_2_word, pred_linear_svc_last_2_word, average='weighted'))\n",
    "print('\\tsvc_linear:', recall_score(y_val_pca, pred_svc_linear, average='weighted'),'\\t\\t', recall_score(y_val_pca_last_word, pred_svc_linear_last_word, average='weighted'), '\\t\\t', recall_score(y_val_pca_last_2_word, pred_svc_linear_last_2_word, average='weighted'))\n",
    "print('\\tsvc_poly:', recall_score(y_val_pca, pred_svc_poly, average='weighted'),'\\t\\t', recall_score(y_val_pca_last_word, pred_svc_poly_last_word, average='weighted'),'\\t\\t', recall_score(y_val_pca_last_2_word, pred_svc_poly_last_2_word, average='weighted'))\n",
    "print('\\tsvc_rbf:', recall_score(y_val_pca, pred_svc_rbf, average='weighted'),'\\t\\t', recall_score(y_val_pca_last_word, pred_svc_rbf_last_word, average='weighted'),'\\t\\t', recall_score(y_val_pca_last_2_word, pred_svc_rbf_last_2_word, average='weighted'))\n",
    "print('\\tANN:', recall_score(np.argmax(y_val_onehot, axis=1), pred_ANN, average='weighted'),'\\t\\t', recall_score(np.argmax(y_val_onehot_last_word, axis=1), pred_ANN_last_word, average='weighted'),'\\t\\t', recall_score(np.argmax(y_val_onehot_last_2_word, axis=1), pred_ANN_last_2_word, average='weighted'))\n",
    "\n",
    "print('Precision')\n",
    "print('\\tno word limit', 'last word', 'last 2 word', sep='\\t\\t\\t\\t')\n",
    "print('\\tlinear_svc:', precision_score(y_val, pred_linear_svc, average='weighted'),'\\t\\t', precision_score(y_val_last_word, pred_linear_svc_last_word, average='weighted'), '\\t\\t', precision_score(y_val_last_2_word, pred_linear_svc_last_2_word, average='weighted'))\n",
    "print('\\tsvc_linear:', precision_score(y_val_pca, pred_svc_linear, average='weighted'),'\\t\\t', precision_score(y_val_pca_last_word, pred_svc_linear_last_word, average='weighted'), '\\t\\t', precision_score(y_val_pca_last_2_word, pred_svc_linear_last_2_word, average='weighted'))\n",
    "print('\\tsvc_poly:', precision_score(y_val_pca, pred_svc_poly, average='weighted'),'\\t\\t', precision_score(y_val_pca_last_word, pred_svc_poly_last_word, average='weighted'),'\\t\\t', precision_score(y_val_pca_last_2_word, pred_svc_poly_last_2_word, average='weighted'))\n",
    "print('\\tsvc_rbf:', precision_score(y_val_pca, pred_svc_rbf, average='weighted'),'\\t\\t', precision_score(y_val_pca_last_word, pred_svc_rbf_last_word, average='weighted'),'\\t\\t', precision_score(y_val_pca_last_2_word, pred_svc_rbf_last_2_word, average='weighted'))\n",
    "print('\\tANN:', precision_score(np.argmax(y_val_onehot, axis=1), pred_ANN, average='weighted'),'\\t\\t', precision_score(np.argmax(y_val_onehot_last_word, axis=1), pred_ANN_last_word, average='weighted'),'\\t\\t', precision_score(np.argmax(y_val_onehot_last_2_word, axis=1), pred_ANN_last_2_word, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison & Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ANN > LinearSVC > SVC(kernel = 'poly') > SVC(kernel = 'rbf') > SVC(kernel = 'poly')\n",
    "- no word limit\t> last 2 word > last word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 普遍上Cross-Validation的表現比Holdout Validation好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_data_word_limit: last 2 word\n",
      "best_model: ANN\n",
      "accuracy: 0.768722713534087\n"
     ]
    }
   ],
   "source": [
    "model_name_list = ['linear_svc', 'svc_linear', 'svc_poly', 'svc_rbf', 'ANN']\n",
    "data_word_limit_name_list = ['no word limit', 'last word', 'last 2 word']\n",
    "accuracy_list = []\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_val, pred_linear_svc))\n",
    "accuracy_list.append(accuracy_score(y_val_pca, pred_svc_linear))\n",
    "accuracy_list.append(accuracy_score(y_val_pca, pred_svc_poly))\n",
    "accuracy_list.append(accuracy_score(y_val_pca, pred_svc_rbf))\n",
    "accuracy_list.append(accuracy_score(np.argmax(y_val_onehot, axis=1), pred_ANN))\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_val_last_word, pred_linear_svc_last_word))\n",
    "accuracy_list.append(accuracy_score(y_val_pca_last_word, pred_svc_linear_last_word))\n",
    "accuracy_list.append(accuracy_score(y_val_pca_last_word, pred_svc_poly_last_word))\n",
    "accuracy_list.append(accuracy_score(y_val_pca_last_word, pred_svc_rbf_last_word))\n",
    "accuracy_list.append(accuracy_score(np.argmax(y_val_onehot_last_word, axis=1), pred_ANN_last_word))\n",
    "\n",
    "accuracy_list.append(accuracy_score(y_val_last_2_word, pred_linear_svc_last_2_word))\n",
    "accuracy_list.append(accuracy_score(y_val_pca_last_2_word, pred_svc_linear_last_2_word))\n",
    "accuracy_list.append(accuracy_score(y_val_pca_last_2_word, pred_svc_poly_last_2_word))\n",
    "accuracy_list.append(accuracy_score(y_val_pca_last_2_word, pred_svc_rbf_last_2_word))\n",
    "accuracy_list.append(accuracy_score(np.argmax(y_val_onehot_last_2_word, axis=1), pred_ANN_last_2_word))\n",
    "\n",
    "best_accuracy_idx = np.argmax(accuracy_list)\n",
    "best_model_name_idx = best_accuracy_idx % len(model_name_list)\n",
    "best_model_name = model_name_list[best_model_name_idx]\n",
    "best_data_word_limit_name_idx = int((best_accuracy_idx - best_model_name_idx) / len(model_name_list))\n",
    "best_data_word_limit_name = data_word_limit_name_list[best_data_word_limit_name_idx]\n",
    "\n",
    "print('best_data_word_limit:', best_data_word_limit_name)\n",
    "print('best_model:', best_model_name)\n",
    "print('accuracy:', np.max(accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model = clone_model(model)\n",
    "ANN_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_list = [linear_svc_model, svc_linear_model, svc_poly_model, svc_rbf_model, ANN_model]\n",
    "\n",
    "if best_data_word_limit_name_idx == 0:\n",
    "    if best_model_name_idx == 0:\n",
    "        x = X\n",
    "        y = Y\n",
    "    elif best_model_name_idx == 4:\n",
    "        x = X\n",
    "        y = Y_onehot\n",
    "    elif best_model_name_idx > 0 and best_data_word_limit_name_idx < 4:\n",
    "        x = X_pca\n",
    "        y = Y\n",
    "elif best_data_word_limit_name_idx == 1:\n",
    "    if best_model_name_idx == 0:\n",
    "        x = X_last_word\n",
    "        y = Y_last_word\n",
    "    elif best_model_name_idx == 4:\n",
    "        x = X_last_word\n",
    "        y = Y_onehot_last_word\n",
    "    elif best_model_name_idx > 0 and best_data_word_limit_name_idx < 4:\n",
    "        x = X_pca_last_word\n",
    "        y = Y_last_word\n",
    "elif best_data_word_limit_name_idx == 2:\n",
    "    if best_model_name_idx == 0:\n",
    "        x = X_last_2_word\n",
    "        y = Y_last_2_word\n",
    "    elif best_model_name_idx == 4:\n",
    "        x = X_last_2_word\n",
    "        y = Y_onehot_last_2_word\n",
    "    elif best_model_name_idx > 0 and best_data_word_limit_name_idx < 4:\n",
    "        x = X_pca_last_2_word\n",
    "        y = Y_last_2_word\n",
    "        \n",
    "best_model = model_list[best_model_name_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "29774/29774 - 1s - loss: 1.7086 - acc: 0.5518\n",
      "Epoch 2/4\n",
      "29774/29774 - 1s - loss: 0.7717 - acc: 0.7764\n",
      "Epoch 3/4\n",
      "29774/29774 - 1s - loss: 0.5162 - acc: 0.8495\n",
      "Epoch 4/4\n",
      "29774/29774 - 1s - loss: 0.3591 - acc: 0.8987\n"
     ]
    }
   ],
   "source": [
    "if best_model_name_idx < 4:\n",
    "    best_model = best_model.fit(x, y)\n",
    "elif best_model_name_idx == 4:\n",
    "    train_model = best_model.fit(x=x, y=y, epochs=4, batch_size=1024, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_json('test.json')\n",
    "if best_data_word_limit_name_idx > 0:\n",
    "    word_limit = best_data_word_limit_name_idx\n",
    "    test_dataset[test_dataset.columns[-1]] = test_dataset[test_dataset.columns[-1]].apply(lambda i : [' '.join(((item.split('(')[0]).split(',')[0]).split()[-word_limit:]) for item in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       10210\n",
      "1        2310\n",
      "2       33213\n",
      "3       16902\n",
      "4        9056\n",
      "        ...  \n",
      "9995     5759\n",
      "9996    47786\n",
      "9997    37976\n",
      "9998    42429\n",
      "9999    12817\n",
      "Name: id, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[test_dataset.columns[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:987: UserWarning: unknown class(es) ['8 juice', 'Artichoke Hearts', 'Baking Blend', 'Bay Leaves', 'Blackened Seasoning', 'Bordelaise sauce', 'Bouillon Powder', 'Budweiser', 'Castelvetrano olives', 'Chambord Liqueur', 'Chartreuse Liqueur', 'Comfort Liqueur', 'Confectioners Sugar', 'Cornbread Mix', 'Creole Seasoning', 'Crushed Tomatoes', 'Elmlea single', 'Fisher Pecans', 'Fume Blanc', 'Garam Masala', 'Garden Parsley', 'Gember Knoflook', 'Gold Tequila', 'Greek Seasoning', 'Greek dressing', 'Heinz Ketchup', 'Ice Cream', 'Italian Sausage', 'Jameson Whiskey', 'Jose Cuervo', 'Kahlua Liqueur', 'Kidney Beans', 'Liquid Aminos', 'Mo Qua', 'Pecan Halves', 'Plus Pasta', 'Sangiovese', 'Sauvignon Blanc', 'Seven Lettuces', 'Spicy Salt', 'Strawberry Kiwi', 'Tea Mix', 'Tomato Ketchup', 'Wok Olie', 'abbamele', 'acai juice', 'aleppo', 'aloe juice', 'and annatto', 'apple rings', 'arctic char', 'arhar', 'arrow root', 'assam', 'awase miso', 'bagel chips', 'bai cai', 'barley grits', 'bean seeds', 'beech mushrooms', 'beet juice', 'biga', 'biscuit crumbs', 'black radish', 'blackpepper', 'blade steak', 'blade steaks', 'braising beef', 'bran flakes', 'branca menta', 'branzino fillets', 'bread yeast', 'brown sauce', 'butter cake', 'butter salt', 'bâtarde', 'cactus', 'cajun remoulade', 'calamari steak', 'candied chestnuts', 'caramel yogurt', 'cashew milk', 'celery powder', 'chees queso', 'cheese curds', 'chestnut powder', 'chicken egg', 'chicken nugget', 'chive blossoms', 'chocolate drink', 'chocolate kisses', 'chocolate pieces', 'chrysanthemum', 'ciabatta loaf', 'citrus peel', 'citrus vinaigrette', 'coconut syrup', 'coffee extract', 'cold-smoked salmon', 'comice pears', 'con carne', 'conch', 'cooked pumpkin', 'cooking salt', 'cornbread crumbs', 'cornmeal mix', 'coulis', 'crabapples', 'cream butter', 'cream pudding', 'cream yogurt', 'crushed pistachio', 'cubed pancetta', 'cumberland sausage', 'curd stick', 'cured pork', 'custard powder', 'dark lager', 'dark soy', 'dasheen', 'de framboise', 'delicata squash', 'demi baguette', 'dessert topping', 'dillweed', 'dipping chocolate', 'do chua', 'dried barberries', 'dried milk', 'dried oysters', 'dried pineapple', 'dried shallots', 'dried tagliatelle', 'duck meat', 'dumpling dough', 'egg beaters', 'eggnog', 'empanada wrappers', 'filipino eggplant', 'filo', 'flaked oats', 'flavored wine', 'flax egg', 'flower petals', 'foccacia', 'forest mushroom', 'free blend', 'free ham', 'fresh dates', 'fruit tropic', 'fuji apples', 'game', 'garbonzo bean', 'garlic juice', 'german mustard', 'ginkgo nut', 'ginseng tea', 'glucose', 'glucose syrup', 'gluten flour', 'gluten-free bread', 'gluten-free broth', 'goma', 'goose', 'grain alcohol', 'grain buns', 'grana', 'granita', 'grilling sauce', 'ground nuts', 'guava paste', 'hake fillets', 'hamachi', 'harusame', 'hoja santa', 'hops', 'instant oats', 'italian rolls', 'jamaican jerk', 'jambalaya', 'jamon serrano', 'japanese peanuts', 'japanese pumpkin', 'jumbo shells', 'karashi', 'ketjap', 'laksa paste', 'lamb cubes', 'lamb kidneys', 'lamb steaks', 'lambrusco', 'langoustines', 'lapsang', 'lapsang souchong', 'large snails', 'lasagna noodle', 'lavender honey', 'lemon pudding', 'licor 43', 'light margarine', 'light tuna', 'lillet', 'lime beverage', 'limeade', 'liver sausage', 'liverwurst', 'loin steak', 'loin steaks', 'lotus leaves', 'madeira wine', 'malt', 'malt powder', 'mantou', 'maraschino', 'margarine spread', 'mashed cauliflower', 'mentsuyu', 'mian', 'microgreens', 'mild sausage', 'mini m&ms', 'minute steaks', 'mora chiles', 'muenster', 'multigrain cereal', 'muscavado sugar', 'natural sugar', 'nonhydrogenated margarine', 'nori furikake', 'nut meal', 'oat groats', 'of veal', 'olive halves', 'orange roughy', 'organic butter', 'pancit bihon', 'panela', 'paprika paste', 'passover wine', 'pasta shapes', 'paste tomato', 'peach juice', 'peach sorbet', 'peach vodka', 'peanut brittle', 'peppered bacon', 'petrale sole', 'picholine', 'piquillo peppers', 'pisco brandy', 'plain chocolate', 'plum wine', 'pork roll', 'pork tail', 'praline topping', 'puff paste', 'pullman loaf', 'pumpernickel', 'purple grapes', 'puy lentils', 'raclette', 'radish slices', 'raspberry sherbet', 'raw milk', 'recipe mix', 'red currants', 'red vinegar', 'ricard', 'rice cereal', 'rice spaghetti', 'ricotta chees', 'rosa sauc', 'roughy fillet', 'royal olives', 'salmon caviar', 'salted pistachios', 'schnapps', 'sea cucumber', 'seafood glaze', 'seasoned cheese', 'seasoned croutons', 'seed butter', 'seed mole', 'seed paste', 'seltzer', 'sharp cheddar', 'shoulder steak', 'shredded bamboo', 'shrimp chips', 'small shells', 'snow crab', 'soy marinade', 'sports drink', 'spot prawns', 'squid tube', 'stock beef', 'strawberry yogurt', 'sturgeon', 'sturgeon fillets', 'style crumbles', 'style rolls', 'suckling pig', 'sugar icing', 'sugar ketchup', 'sugar pearls', 'sushi vinegar', 'sweet chorizo', 'swiss', 'swiss steak', 'table syrup', 'tallow', 'tart filling', 'tea concentrate', 'the woods', 'tip steak', 'toffee sauce', 'tomato jam', 'tonic water', 'trout caviar', 'turkey breasts', 'turkey burger', 'turkey sausages', 'v8', 'valencia rice', 'veal escalopes', 'veal loin', 'venison steaks', 'watermelon radishes', 'wensleydale', 'white yellow', 'winter savory', 'with beans', 'wood mushrooms', 'xuxu', 'yam bean', 'yeast flakes'] will be ignored\n",
      "  .format(sorted(unknown, key=str)))\n"
     ]
    }
   ],
   "source": [
    "x_test = test_dataset[test_dataset.columns[-1]]\n",
    "if best_data_word_limit_name_idx == 0:\n",
    "    x_test = pd.DataFrame(mlb.transform(x_test), columns=mlb.classes_, index=x_test.index)\n",
    "elif best_data_word_limit_name_idx == 1:\n",
    "    x_test = pd.DataFrame(mlb_last_word.transform(x_test), columns=mlb_last_word.classes_, index=x_test.index)\n",
    "elif best_data_word_limit_name_idx == 2:\n",
    "    x_test = pd.DataFrame(mlb_last_2_word.transform(x_test), columns=mlb_last_2_word.classes_, index=x_test.index) \n",
    "x_test = np.array(x_test)\n",
    "x_test = x_test.astype(float)\n",
    "\n",
    "# if best_model_name_idx > 0 and best_model_name_idx < 4:\n",
    "#     if best_data_word_limit_name_idx == 0:\n",
    "#         n_com_begin = 500\n",
    "#     elif best_data_word_limit_name_idx == 1:\n",
    "#         n_com_begin = 105\n",
    "#     elif best_data_word_limit_name_idx == 2:\n",
    "#         n_com_begin = 380\n",
    "#     x_test, x_test_proper_n_com, x_test_explained_ratio = pca_with_proper_n_com(x_test, n_com_begin) \n",
    "#     print('n_com:', x_test_proper_n_com, 'explained variance ratio:', x_test_explained_ratio)\n",
    "\n",
    "if best_model_name_idx > 0 and best_model_name_idx < 4:\n",
    "    if best_data_word_limit_name_idx == 0:\n",
    "        n_com = X_proper_n_com\n",
    "    elif best_data_word_limit_name_idx == 1:\n",
    "        n_com = X_proper_n_com_last_word\n",
    "    elif best_data_word_limit_name_idx == 2:\n",
    "        n_com = X_proper_n_com_last_2_word\n",
    "    \n",
    "    pca = PCA(n_components = n_com)\n",
    "    x_test = pca.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model_name_idx < 4:\n",
    "    pred_y = best_model.predict(x_test)\n",
    "elif best_model_name_idx == 4:\n",
    "    pred_y = best_model.predict_classes(x_test)\n",
    "    if best_data_word_limit_name_idx == 0:\n",
    "        pred_y = Y_le_model.inverse_transform(pred_y)\n",
    "    elif best_data_word_limit_name_idx == 1:\n",
    "        pred_y = Y_le_model_last_word.inverse_transform(pred_y)\n",
    "    elif best_data_word_limit_name_idx == 2:\n",
    "        pred_y = Y_le_model_last_2_word.inverse_transform(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.drop(columns=test_dataset.columns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(list(test_dataset[test_dataset.columns[0]]), columns=['Id'])\n",
    "df_2 = pd.DataFrame(pred_y, columns=['Category'])\n",
    "y_test = pd.concat([df_1, df_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Id      Category\n",
      "0     10210       italian\n",
      "1      2310  cajun_creole\n",
      "2     33213       mexican\n",
      "3     16902        indian\n",
      "4      9056       mexican\n",
      "...     ...           ...\n",
      "9995   5759       italian\n",
      "9996  47786    vietnamese\n",
      "9997  37976      japanese\n",
      "9998  42429        indian\n",
      "9999  12817       italian\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write prediction to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv('/home/maomao/y_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
